2025-12-20 07:52:27,031 - {'optimizer': {'name': 'adam', 'lr': 0.001, 'weight_decay': 0}, 'train': {'epoch': 50, 'batch_size': 512, 'save_model': True, 'log_loss': False, 'test_step': 1, 'reproducible': True, 'seed': 2023, 'early_stop': False}, 'test': {'metrics': ['mrr', 'ndcg'], 'k': [5, 10, 20], 'batch_size': 512}, 'data': {'type': 'sequential', 'name': 'ml-20m', 'seq_aug': True, 'dir': './datasets/sequential/ml-20m_seq/', 'user_num': 96726, 'item_num': 10154}, 'model': {'name': 'mgrec', 'dropout_rate': 0.1, 'graph_dropout_prob': 0.3, 'n_layers': 2, 'embedding_size': 64, 'n_heads': 2, 'max_seq_len': 50, 'cl_lambda': 0.0001, 'cl_temp': 0.8, 'weight_mean': 0.4, 'sim_group_k': 4, 'kl_weight': 0.01}, 'tune': {'enable': False, 'hyperparameters': ['cl_lambda', 'weight_mean'], 'cl_lambda': [0.0001, 0.001, 0.01], 'weight_mean': [0.4, 0.5, 0.6]}, 'device': 'cuda'}
2025-12-20 07:52:28,300 - The size of tensor a (512) must match the size of tensor b (64) at non-singleton dimension 1
Traceback (most recent call last):
  File "/workspace/MGRec/trainer/utils.py", line 15, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/MGRec/trainer/trainer.py", line 94, in train
    self.train_epoch(model, epoch_idx)
  File "/workspace/MGRec/trainer/trainer.py", line 65, in train_epoch
    loss, loss_dict = model.cal_loss(batch_data)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/MGRec/models/sequential/mgrec.py", line 217, in cal_loss
    attn_transition_emb = recency_attention(transition_graph_emb[batch_seqs])
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/MGRec/models/sequential/mgrec.py", line 89, in recency_attention
    new_item_emb = (attn.unsqueeze(-1) * item_emb).sum(dim=1) / seq_len.unsqueeze(-1)       # (B, D)
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~
RuntimeError: The size of tensor a (512) must match the size of tensor b (64) at non-singleton dimension 1
